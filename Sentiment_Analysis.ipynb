{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k61JvAcquC1U",
        "outputId": "dd3fea08-9e96-466d-d971-84e83709a783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy : 0.81\n",
            "\n",
            " Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.78      0.86      0.82       199\n",
            "         pos       0.85      0.76      0.80       201\n",
            "\n",
            "    accuracy                           0.81       400\n",
            "   macro avg       0.81      0.81      0.81       400\n",
            "weighted avg       0.81      0.81      0.81       400\n",
            "\n",
            "prediction: pos\n",
            "prediction: neg\n"
          ]
        }
      ],
      "source": [
        "# Sentiment Analysis using \"Machine learning\".\n",
        "# This project uses \"Natural Language Processing\" (NLP) techniques to classify text (e.g., reviews or tweets) as Positive, Negative, or Neutral.\n",
        "# step 1:\n",
        "! pip install pandas numpy matplotlib seaborn nltk scikit-learn              # installing Required Libraries\n",
        "# step 2:\n",
        "import pandas as pd                                                          # import pandas and call it pd\n",
        "import numpy as np                                                           # import numpy and call it np\n",
        "import seaborn as sns                                                        # import seaborn and call it sns (for plotting)\n",
        "import matplotlib.pyplot as plt                                              # import matpltlib and call it plt(for plotting)\n",
        "import nltk                                                                  # importing the Natural Language Toolkit library for text processing and sentiment analysis\n",
        "from nltk.corpus import stopwords                                            # imports a list of common words (like \"the\", \"is\", \"and\") that are usually removed in text preprocessing\n",
        "from sklearn.model_selection import train_test_split                         # To divide the data into training and testing parts\n",
        "from sklearn.feature_extraction.text import CountVectorizer                  # To Converts text into numerical data (word counts) so machine learning models can understand it\n",
        "from sklearn.naive_bayes import MultinomialNB                                # Imports the Naive Bayes algorithm used for text classification (like spam detection or sentiment analysis)\n",
        "from sklearn.metrics import accuracy_score,classification_report             # Measures how good the model is\n",
        "# step 3:\n",
        "nltk.download('stopwords')                                                   # Downloads the list of common stopwords (like \"the\", \"is\", \"and\") used to clean text data\n",
        "# step 4:\n",
        "nltk.download('movie_reviews')                                               # Download dataset\n",
        "from nltk.corpus import movie_reviews                                        # Imports sample movie reviews dataset with labels (positive/negative)\n",
        "import random                                                                # Used to randomly shuffle the reviews for better training\n",
        "documents = [(list(movie_reviews.words(fileid)),category)\n",
        "             for category in movie_reviews.categories()\n",
        "             for fileid in movie_reviews.fileids(category)]                  # Load the movie review dataset and prepare it\n",
        "# step 5:\n",
        "stop_words= stopwords.words('english')                                       # clean the text data.Loads english stopwords (common words to remove)\n",
        "def clean_text(text):\n",
        "  words=text.lower().split()                                                 # convert to lower case and split into words\n",
        "  words=[word for word in words if word.isalpha()and word not in stop_words]\n",
        "  return ' '.join(words)                                                     # join words back to one string.\n",
        "data = pd.DataFrame(documents, columns=['Review', 'Sentiment'])\n",
        "data['Review'] = [' '.join(words) for words in data['Review']]\n",
        "data['Cleaned_Review'] = data['Review'].apply(clean_text)                    # This cleans every single review using your clean_text() function\n",
        "# step 6:\n",
        "vectorizer = CountVectorizer()\n",
        "x=vectorizer.fit_transform(data['Cleaned_Review'])                           # Converts text into numbers each word gets a number\n",
        "y=data['Sentiment']                                                          # target variable (positive or negative)\n",
        "# step 7:\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42) # splitting the data into testing and training\n",
        "# step 8:\n",
        "model=MultinomialNB()                                                        # Load \"NaiveBayes\" model\n",
        "model.fit(x_train,y_train)                                                   # train the model using train data\n",
        "# step 9:\n",
        "# Predict and check accuracy\n",
        "y_pred=model.predict(x_test)                                                 # Use model to predict label (positive/negative)\n",
        "print (\"Accuracy :\",accuracy_score(y_test,y_pred))                           # print how many predictions were correct\n",
        "print(\"\\n Classification Report:\\n\",classification_report(y_test,y_pred))\n",
        "# step 10:\n",
        "# Give your own reviews to the test model.\n",
        "my_review = [\" The Movie was really fantastic and enjoyable\"]\n",
        "my_review_vector = vectorizer.transform(my_review)                          # clean and convert to numbers\n",
        "prediction = model.predict(my_review_vector)                                 # predict sentiment\n",
        "print(\"prediction:\",prediction[0])\n",
        "# second review\n",
        "second_review = [\" The Movie was too bad\"]\n",
        "second_review_vector = vectorizer.transform(second_review)\n",
        "prediction = model.predict(second_review_vector)\n",
        "print(\"prediction:\",prediction[0])"
      ]
    }
  ]
}